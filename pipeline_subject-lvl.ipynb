{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject level parcellation\n",
    "This juypter pipeline is used to perform a parcelllation on the subject level.\n",
    "Each subject can i their personalized parcellation using their resting state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "from parcellation_surface.preprocessing_surface import load_data_normalized\n",
    "from parcellation_surface.similarity_matrix import compute_similarity_matrix_pca\n",
    "from parcellation_surface.smoothing import smooth_surface_graph\n",
    "from parcellation_surface.gradient import compute_gradients, build_mesh_graph\n",
    "from parcellation_surface.watershed import watershed_by_flooding\n",
    "from parcellation_surface.visualization import visualize_brain_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell follows the literature method, but is time-consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline subject level\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Start modification \n",
    "config = {\n",
    "\"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "\"subjects_dir\": Path(r\"D:\\Data_Conn_Preproc\\PPSFACE_N18\")\n",
    "}\n",
    "run = 1\n",
    "subject = f\"{2:02d}\" #TODO : choose the subject number\n",
    "subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "# Output paths\n",
    "output_dir = subj_dir / f\"sub-{subject}_parcellation\"\n",
    "(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>> end modification\n",
    "\n",
    "for hemisphere in ['lh', 'rh']:\n",
    "    #TODO: remove this line afterwards\n",
    "    if hemisphere == 'rh':\n",
    "       continue\n",
    "    print(f\"\\n\\n\\nProcessing subject {subject} hemisphere {hemisphere}\\n\\n\\n\")\n",
    "    \n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Start modification \n",
    "    # Surface paths\n",
    "    surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.white\"\n",
    "    surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.inflated\"\n",
    "    # Fmri paths\n",
    "    surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "    vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "    brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> end modification\n",
    "\n",
    "    # Extract the Surface Mesh\n",
    "    coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "    coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "    graph = build_mesh_graph(faces)\n",
    "\n",
    "    # Load the data\n",
    "    surf_fmri_n, vol_fmri_n = load_data_normalized(surf_fmri_path,\n",
    "                                                    vol_fmri_path, \n",
    "                                                    brain_mask_path)\n",
    "    # 1 : Compute the similarity matrix\n",
    "    print('Computing similarity matrix')\n",
    "    sim_matrix = compute_similarity_matrix_pca(vol_fmri_n,\n",
    "                                               surf_fmri_n)\n",
    "\n",
    "    # Save the similarty matrix\n",
    "    # sim_matrix_path = output_dir / f\"sim_matrix_sub{subject}_run{run}_{hemisphere}.npy\"\n",
    "    # np.save(sim_matrix_path, sim_matrix)\n",
    "    \n",
    "        \n",
    "    # 2 : Smooth the similatry matrix\n",
    "    print('Smoothing similarity matrix')\n",
    "    sim_matrix_smoothed = smooth_surface_graph(graph, sim_matrix, iterations=5)\n",
    "\n",
    "    # 3 : Compute the gradient of the similarty matrix\n",
    "    print('Computing gradients')\n",
    "    gradients = compute_gradients(graph, sim_matrix_smoothed)\n",
    "\n",
    "    # 3.1 : Smooth the gradient\n",
    "    print('Smoothing gradients')\n",
    "    gradients_smoothed = smooth_surface_graph(graph, gradients, iterations=10)\n",
    "    gradients_path = output_dir / f\"gradients_smoothed_sub{subject}_run{run}_{hemisphere}.npy\"\n",
    "    np.save(gradients_path, gradients_smoothed)\n",
    "\n",
    "    # 4 : Create the boundary map from the watershed\n",
    "    boundary_map = np.zeros_like(gradients[:,0]).astype(np.float32)\n",
    "    for map_idx in range(gradients.shape[1]): # loop over each columns of the matrix\n",
    "        if map_idx % 10 == 0:\n",
    "            print(f\"Processing map {map_idx}\") # Print the current map index\n",
    "        boundary = (watershed_by_flooding(graph, gradients_smoothed[:,map_idx])<0)*1 # Extract the bounary from the watershed algorithm\n",
    "        boundary_map += boundary\n",
    "    \n",
    "    boundary_map_path = output_dir / f\"boundary_map_sub{subject}_run{run}_{hemisphere}.npy\"\n",
    "    np.save(boundary_map_path, boundary_map)\n",
    "    # memory clean up\n",
    "    del boundary_map, gradients, gradients_smoothed, sim_matrix, sim_matrix_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Cell is faster but doesn't follow the litterature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline subject level\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Start modification \n",
    "config = {\n",
    "\"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "\"subjects_dir\": Path(r\"D:\\Data_Conn_Preproc\\PPSFACE_N18\")\n",
    "}\n",
    "run = 1\n",
    "subject = f\"{10:02d}\" #TODO : choose the subject number\n",
    "subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "# Output paths\n",
    "output_dir = subj_dir / f\"sub-{subject}_parcellation\"\n",
    "(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>> end modification\n",
    "\n",
    "for hemisphere in ['lh', 'rh']:\n",
    "\n",
    "    print(f\"\\n\\n\\nProcessing subject {subject} hemisphere {hemisphere}\\n\\n\\n\")\n",
    "    \n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Start modification \n",
    "    # Surface paths\n",
    "    surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.white\"\n",
    "    surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.inflated\"\n",
    "    # Fmri paths\n",
    "    surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "    vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "    brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> end modification\n",
    "\n",
    "    # Extract the Surface Mesh\n",
    "    coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "    coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "    graph = build_mesh_graph(faces)\n",
    "\n",
    "    # Load the data\n",
    "    surf_fmri_n, vol_fmri_n = load_data_normalized(surf_fmri_path,\n",
    "                                                    vol_fmri_path, \n",
    "                                                    brain_mask_path)\n",
    "    # 1 : Compute the similarity matrix\n",
    "    print('Computing similarity matrix')\n",
    "    sim_matrix = compute_similarity_matrix_pca(vol_fmri_n,\n",
    "                                               surf_fmri_n)\n",
    "\n",
    "    # Save the similarty matrix\n",
    "    # sim_matrix_path = output_dir / f\"sim_matrix_sub{subject}_fastway_run{run}_{hemisphere}.npy\"\n",
    "    # np.save(sim_matrix_path, sim_matrix)\n",
    "    \n",
    "        \n",
    "    # 2 : Smooth the similatry matrix\n",
    "    print('Smoothing similarity matrix')\n",
    "    sim_matrix_smoothed = smooth_surface_graph(graph, sim_matrix, iterations=5)\n",
    "\n",
    "    # 3 : Compute the gradient of the similarty matrix\n",
    "    print('Computing gradients')\n",
    "    gradients = compute_gradients(graph, sim_matrix_smoothed)\n",
    "\n",
    "    # 3.1 : Smooth the gradient\n",
    "    print('Smoothing gradients')\n",
    "    gradients_smoothed = smooth_surface_graph(graph, gradients, iterations=10)\n",
    "    gradients_path = output_dir / f\"gradients_smoothed_sub{subject}_fastway_run{run}_{hemisphere}.npy\"\n",
    "    np.save(gradients_path, gradients_smoothed)\n",
    "\n",
    "    # 4 : Create the boundary map from the grad mean\n",
    "    boundary_map = gradients_smoothed.mean(axis=1)\n",
    "    \n",
    "    boundary_map_path = output_dir / f\"boundary_map_sub{subject}_fastway_run{run}_{hemisphere}.npy\"\n",
    "    np.save(boundary_map_path, boundary_map)\n",
    "    # memory clean up\n",
    "    del boundary_map, gradients, gradients_smoothed, sim_matrix, sim_matrix_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results of subject level parcellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 : Visualize the bounardy map\n",
    "config = {\n",
    "\"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "\"subjects_dir\": Path(r\"D:\\Data_Conn_Preproc\\PPSFACE_N18\")\n",
    "}\n",
    "subject = f\"{3:02d}\"\n",
    "\n",
    "surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"lh.inflated\"\n",
    "surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"lh.white\"\n",
    "\n",
    "coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "graph = build_mesh_graph(faces)\n",
    "\n",
    "path_bound = f\"D:\\Data_Conn_Preproc\\PPSFACE_N18\\sub-{subject}\\sub-{subject}_parcellation\\boundary_map_sub{subject}_run1_lh.npy\"\n",
    "boundary_map = np.load(path_bound)\n",
    "print('boundary_map shape', boundary_map.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_brain_surface(coords_, faces_, boundary_map, title=f'Boundary map Subject n°{subject}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_smoothed = smooth_surface_graph(graph, boundary_map, iterations=10)\n",
    "visualize_brain_surface(coords_, faces_, bound_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = watershed_by_flooding(graph, bound_smoothed)\n",
    "visualize_brain_surface(coords_, faces_, labels, title=f'Parcellation of subject n°{subject}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
