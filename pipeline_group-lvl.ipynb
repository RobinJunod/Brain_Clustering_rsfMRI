{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group-lvl parcellation : from the average of the Similatriy Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import nibabel as nib \n",
    "import networkx as nx\n",
    "\n",
    "from parcellation_surface.preprocessing_surface import load_data_normalized\n",
    "from parcellation_surface.similarity_matrix import compute_similarity_matrix_pca\n",
    "from parcellation_surface.smoothing import smooth_surface_graph\n",
    "from parcellation_surface.gradient import compute_gradients, build_mesh_graph\n",
    "from parcellation_surface.watershed import watershed_by_flooding\n",
    "from parcellation_surface.visualization import visualize_brain_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the cell below for a Gordon like parcellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>>>>>>>>>>>>>>>>>>>>>>>> To modify if needed\n",
    "dataset = 'PPSFACE_N18'\n",
    "run = 1\n",
    "config = {\n",
    "\"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "\"subjects_dir\": Path(f\"D:\\Data_Conn_Preproc\\{dataset}\")\n",
    "}\n",
    "# Output paths\n",
    "output_dir = config[\"subjects_dir\"] / \"group_parcellation\"\n",
    "(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "for hemisphere in ['lh', 'rh']:\n",
    "    \n",
    "    surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.white\"\n",
    "    surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.inflated\"\n",
    "    # Extract the Surface Mesh\n",
    "    coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "    coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "    graph = build_mesh_graph(faces)\n",
    "    \n",
    "    # 1 : Compute the average similartiy matrix across each subjects\n",
    "    sim_matrix_sum = np.zeros(nx.adjacency_matrix(graph).shape, dtype=np.float32)\n",
    "    print('sim_matrix_sum shape', sim_matrix_sum.shape)\n",
    "    for i in range(1,19):\n",
    "        if i == 5 and dataset == 'PPSFACE_N20':\n",
    "            continue # Subject 5 is missing PPSFACE20\n",
    "        \n",
    "        # >>>>>>>>>>>>>>>>>>> To modify if needed\n",
    "        # Variables path\n",
    "        subject = f\"{i:02d}\"\n",
    "        subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "\n",
    "        # Define paths using pathlib\n",
    "        surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "        vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "        brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "        # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "        \n",
    "        # Load the data\n",
    "        surf_fmri_n, vol_fmri_n = load_data_normalized(surf_fmri_path,\n",
    "                                                       vol_fmri_path, \n",
    "                                                       brain_mask_path)\n",
    "        \n",
    "        sim_matrix_sum += compute_similarity_matrix_pca(vol_fmri_n,\n",
    "                                                       surf_fmri_n)\n",
    "\n",
    "    # Save the similarty matrix\n",
    "    sim_matrix_path = output_dir / f\"similarity_matrix_group_run{run}_{hemisphere}.npy\"\n",
    "    np.save(sim_matrix_path, sim_matrix_sum)\n",
    "    \n",
    "    # 2 : Smooth the similatry matrix\n",
    "    sim_matrix_smoothed = smooth_surface_graph(graph, sim_matrix_sum, iterations=5)\n",
    "\n",
    "    # 3 : Compute the gradient of the similarty matrix\n",
    "    gradients = compute_gradients(graph, sim_matrix_smoothed)\n",
    "\n",
    "    # 3.1 : Smooth the gradient\n",
    "    gradients_smoothed = smooth_surface_graph(graph, gradients, iterations=10)\n",
    "    gradients_path = output_dir / f\"gradients_smoothed_group_run{run}_{hemisphere}.npy\"\n",
    "    np.save(gradients_path, gradients_smoothed)\n",
    "\n",
    "    # 4 : Create the boundary map from the watershed\n",
    "    boundary_map = np.zeros_like(gradients[:,0]).astype(np.float32)\n",
    "    for map_idx in range(gradients.shape[1]): # loop over each columns of the matrix\n",
    "        if map_idx % 10 == 0:\n",
    "            print(f\"Processing map {map_idx}\") # Print the current map index\n",
    "        boundary = (watershed_by_flooding(graph, gradients_smoothed[:,map_idx])<0)*1 # Extract the bounary from the watershed algorithm\n",
    "        boundary_map += boundary\n",
    "    boundary_map_path = output_dir / f\"boundary_map_group_run{run}_{hemisphere}.npy\"\n",
    "    np.save(boundary_map_path, boundary_map)\n",
    "\n",
    "    # Create the FINAL parcels\n",
    "    bound_smoothed = smooth_surface_graph(graph, boundary_map, iterations=10)\n",
    "    label_bound = watershed_by_flooding(graph, bound_smoothed)\n",
    "    # Save the parcels\n",
    "    np.save(output_dir / f\"labels_group_run12_smooth10_run{run}_{hemisphere}.npy\", label_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Cell is faster but doesn't follow the litterature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>>>>>>>>>>>>>>>>>>>>>>>> To modify if needed\n",
    "dataset = 'PPSFACE_N18'\n",
    "run = 1\n",
    "config = {\n",
    "\"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "\"subjects_dir\": Path(f\"D:\\Data_Conn_Preproc\\{dataset}\")\n",
    "}\n",
    "# Output paths\n",
    "output_dir = config[\"subjects_dir\"] / \"group_parcellation\"\n",
    "(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "for hemisphere in ['lh', 'rh']:\n",
    "    \n",
    "    surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.white\"\n",
    "    surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.inflated\"\n",
    "    # Extract the Surface Mesh\n",
    "    coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "    coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "    graph = build_mesh_graph(faces)\n",
    "    \n",
    "    # 1 : Compute the average similartiy matrix across each subjects\n",
    "    sim_matrix_sum = np.zeros(nx.adjacency_matrix(graph).shape, dtype=np.float32)\n",
    "    print('sim_matrix_sum shape', sim_matrix_sum.shape)\n",
    "    for i in range(1,19):\n",
    "        if i == 5 and dataset == 'PPSFACE_N20':\n",
    "            continue # Subject 5 is missing PPSFACE20\n",
    "        \n",
    "        # >>>>>>>>>>>>>>>>>>> To modify if needed\n",
    "        # Variables path\n",
    "        subject = f\"{i:02d}\"\n",
    "        subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "\n",
    "        # Define paths using pathlib\n",
    "        surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "        vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "        brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "        # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "        \n",
    "        # Load the data\n",
    "        surf_fmri_n, vol_fmri_n = load_data_normalized(surf_fmri_path,\n",
    "                                                       vol_fmri_path, \n",
    "                                                       brain_mask_path)\n",
    "        \n",
    "        sim_matrix_sum += compute_similarity_matrix_pca(vol_fmri_n,\n",
    "                                                       surf_fmri_n)\n",
    "\n",
    "    # Save the similarty matrix\n",
    "    # sim_matrix_path = output_dir / f\"similarity_matrix_group_fastway_run{run}_{hemisphere}.npy\"\n",
    "    # np.save(sim_matrix_path, sim_matrix_sum)\n",
    "    \n",
    "    # 2 : Smooth the similatry matrix\n",
    "    sim_matrix_smoothed = smooth_surface_graph(graph, sim_matrix_sum, iterations=5)\n",
    "\n",
    "    # 3 : Compute the gradient of the similarty matrix\n",
    "    gradients = compute_gradients(graph, sim_matrix_smoothed)\n",
    "\n",
    "    # 3.1 : Smooth the gradient\n",
    "    gradients_smoothed = smooth_surface_graph(graph, gradients, iterations=10)\n",
    "    gradients_path = output_dir / f\"gradients_smoothed_group_fastway_run{run}_{hemisphere}.npy\"\n",
    "    np.save(gradients_path, gradients_smoothed)\n",
    "\n",
    "    # 4 : Create the boundary map from the watershed\n",
    "    boundary_map = gradients_smoothed.mean(axis=1)\n",
    "\n",
    "    # Create the FINAL parcels\n",
    "    bound_smoothed = smooth_surface_graph(graph, boundary_map, iterations=10)\n",
    "    label_bound = watershed_by_flooding(graph, bound_smoothed)\n",
    "    # Save the parcels\n",
    "    np.save(output_dir / f\"labels_group_fastway_smooth10_run{run}_{hemisphere}.npy\", label_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING BEFOR USING THIS SCRIPT\n",
    "\"\"\"\n",
    "This part is used in order to create a parcellation from the run1 and run2.\n",
    "\"\"\"\n",
    "ppsface = \"PPSFACE_N20\"\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "   surface_path = f\"D:\\Data_Conn_Preproc\\\\fsaverage6\\surf\\{hemi}.white\"\n",
    "   inf_path = f\"D:\\Data_Conn_Preproc\\\\fsaverage6\\surf\\{hemi}.inflated\"\n",
    "   # surface_path = r\"D:\\Data_Conn_Preproc\\fsaverage6\\surf\\rh.inflated\"\n",
    "   coords, faces = nib.freesurfer.read_geometry(surface_path)\n",
    "   coords_, faces_ = nib.freesurfer.read_geometry(inf_path)\n",
    "   graph = build_mesh_graph(faces)\n",
    "   bound_sum = 0\n",
    "   for run in [\"1\",\"2\"]:\n",
    "      # Extract the parcellation\n",
    "      bound_sum += np.load(f\"D:\\Data_Conn_Preproc\\{ppsface}\\group_parcellation\\\\boundary_map_group_run{run}_{hemi}.npy\")\n",
    "        \n",
    "   # Create the parcels\n",
    "   bound_smoothed = smooth_surface_graph(graph, bound_sum, iterations=10)\n",
    "   label_bound = watershed_by_flooding(graph, bound_smoothed)\n",
    "   # Save the parcels\n",
    "   np.save(f\"D:\\Data_Conn_Preproc\\{ppsface}\\group_parcellation\\labels_group_run12_smooth10_{hemi}.npy\", label_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 : Visualize the bounardy map\n",
    "config = {\n",
    "\"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "\"subjects_dir\": Path(r\"D:\\Data_Conn_Preproc\\PPSFACE_N20\")\n",
    "}\n",
    "run = 2\n",
    "surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"lh.inflated\"\n",
    "surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"lh.white\"\n",
    "\n",
    "coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "graph = build_mesh_graph(faces)\n",
    "\n",
    "\n",
    "\n",
    "# path_sim_mtrx = r\"D:\\Data_Conn_Preproc\\PPSFACE_N18\\group_parcellation\\similarity_matrix_group_run1_lh.npy\"\n",
    "# sim_mtrx = np.load(path_sim_mtrx)\n",
    "path_grad = r\"D:\\Data_Conn_Preproc\\PPSFACE_N18\\group_parcellation\\gradients_smoothed_group_run1_lh.npy\"\n",
    "grad = np.load(path_grad)\n",
    "\n",
    "print('sim_mtrx shape', grad.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parcellation_surface.smoothing import smooth_surface_graph\n",
    "\n",
    "grad_s = smooth_surface_graph(graph, grad[:,10], iterations=10)\n",
    "label_bound = watershed_by_flooding(graph, grad_s)\n",
    "visualize_brain_surface(coords_, faces_, (label_bound<0)*1, title='Bounardy Map lh PPSFACE20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_smoothed = smooth_surface_graph(graph, boundary_map, iterations=10)\n",
    "visualize_brain_surface(coords_, faces_, bound_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = watershed_by_flooding(graph, bound_smoothed)\n",
    "visualize_brain_surface(coords_, faces_, labels, title=\"Group-Level Parcellation lh PPSFACE20\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
