{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO : create a parcellation from the average of the similatriy matrix,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import nibabel as nib \n",
    "import networkx as nx\n",
    "\n",
    "from similarity_matrix import compute_similarity_matrix_pca\n",
    "from smoothing import smooth_surface_graph\n",
    "from gradient import compute_gradients, build_mesh_graph\n",
    "from watershed import watershed_by_flooding\n",
    "\n",
    "from visualization import visualize_brain_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path Run all subject lh on run 1\n",
    "\n",
    "# config = {\n",
    "# \"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "# \"subjects_dir\": Path(r\"D:\\Data_Conn_Preproc\\PPSFACE_N20\")\n",
    "# }\n",
    "\n",
    "# hemisphere = 'lh'\n",
    "# run = 2\n",
    "\n",
    "# surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.white\"\n",
    "# surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.inflated\"\n",
    "# # Extract the Surface Mesh\n",
    "# coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "# coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "# graph = build_mesh_graph(faces)\n",
    "\n",
    "# # Output paths\n",
    "# output_gradient_dir = config[\"subjects_dir\"] / \"gradient\"\n",
    "# (output_gradient_dir).mkdir(exist_ok=True, parents=True)\n",
    "# output_labels_dir = config[\"subjects_dir\"] / \"labels\"\n",
    "# (output_labels_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "\n",
    "# # Variables path\n",
    "# subject = f\"{1:02d}\"\n",
    "# subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "\n",
    "# # Define paths using pathlib\n",
    "# surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "# vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "# brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "\n",
    "\n",
    "# # If needed, the grey matter mask\n",
    "# # gm_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / f\"{hemisphere}.ribbon.mgz\"\n",
    "\n",
    "\n",
    "# print('all paths defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import resample_img\n",
    "def load_data_normalized(surf_fmri_path,\n",
    "                         vol_fmri_path, \n",
    "                         brain_mask_path):\n",
    "\n",
    "    # Load the surface data\n",
    "    surf_fmri = nib.load(str(surf_fmri_path)).get_fdata().squeeze()\n",
    "    surf_fmri_n = (surf_fmri - np.mean(surf_fmri, axis=1, keepdims=True)) / np.std(surf_fmri, axis=1, keepdims=True)\n",
    "    \n",
    "    # Load the images using nibabel\n",
    "    vol_fmri = nib.load(str(vol_fmri_path))\n",
    "    mask_img = nib.load(brain_mask_path)\n",
    "\n",
    "    # resample the mask to the right one\n",
    "    mask_img = resample_img(\n",
    "        mask_img,\n",
    "        target_affine=vol_fmri.affine,\n",
    "        target_shape=vol_fmri.get_fdata().shape[:-1],\n",
    "        interpolation='nearest',\n",
    "        force_resample=True\n",
    "    )\n",
    "\n",
    "    fmri_data = vol_fmri.get_fdata()\n",
    "    mask_data = mask_img.get_fdata().astype(bool)  # Convert mask to boolean\n",
    "    # Normalize the data\n",
    "    vol_fmri = fmri_data[mask_data] \n",
    "    vol_fmri_n = (vol_fmri - np.mean(vol_fmri, axis=1, keepdims=True)) / np.std(vol_fmri, axis=1, keepdims=True)\n",
    "    \n",
    "    # Remove nans from the data\n",
    "    surf_fmri_n = np.nan_to_num(surf_fmri_n).astype(np.float32)\n",
    "    vol_fmri_n = np.nan_to_num(vol_fmri_n).astype(np.float32)\n",
    "    return surf_fmri_n, vol_fmri_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def compute_similarty_matrix_PCA(vol_fmri_n,\n",
    "                                 surf_fmri_n,\n",
    "                                 n_components=17):\n",
    "    \"\"\"Compute the similarity matrix with a PCA dim reduction\n",
    "    Args:\n",
    "        vol_fmri_n (_type_): _description_\n",
    "        surf_fmri_n (_type_): _description_\n",
    "        n_components (int, optional): _description_. Defaults to 17.\n",
    "    \"\"\"\n",
    "    # 4. Run PCA on the time series data\n",
    "    n_components = 17  # Number of PCA components you want to extract\n",
    "    pca = PCA(n_components=n_components)\n",
    "    temporal_modes = pca.fit_transform(vol_fmri_n.T).astype(np.float32) # shape = (n_timepoints, n_components)\n",
    "    \n",
    "    # Correlation formula for normalized data\n",
    "    corr_matrix = (surf_fmri_n @ temporal_modes)  / (surf_fmri_n.shape[1] - 1) # shape = (n_vertices, n_components)\n",
    "    # Similarty matrix\n",
    "    sim_matrix = np.corrcoef(corr_matrix, dtype=np.float32) # shape = (n_vertices, n_vertices)\n",
    "    sim_matrix = np.nan_to_num(sim_matrix) # remove nans if any\n",
    "    return sim_matrix\n",
    "\n",
    "from similarity_matrix import compute_similarity_matrix_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Full pipeline my way\n",
    "    \n",
    "# # 1 : Compute the average similartiy matrix across each subjects\n",
    "# sim_matrix_sum = np.zeros(nx.adjacency_matrix(graph).shape, dtype=np.float32)\n",
    "# print('sim_matrix_sum shape', sim_matrix_sum.shape)\n",
    "# for i in range(1,21):\n",
    "#     if i == 5:\n",
    "#         continue # Subject 5 is missing\n",
    "#     # Variables path\n",
    "#     subject = f\"{i:02d}\"\n",
    "#     subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "\n",
    "#     # Define paths using pathlib\n",
    "#     surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "#     vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "#     brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "\n",
    "#     # Load the data\n",
    "#     surf_fmri_n, vol_fmri_n = load_data_normalized(surf_fmri_path,\n",
    "#                                                     vol_fmri_path, \n",
    "#                                                     brain_mask_path)\n",
    "    \n",
    "#     sim_matrix_sum += compute_similarty_matrix_PCA(vol_fmri_n,\n",
    "#                                                 surf_fmri_n)\n",
    "\n",
    "# # Save the similarty matrix\n",
    "# sim_matrix_path = config[\"subjects_dir\"] / f\"similarity_matrix_group_run{run}_{hemisphere}.npy\"\n",
    "# np.save(sim_matrix_path, sim_matrix_sum)\n",
    "    \n",
    "    \n",
    "# # 2 : Smooth the similatry matrix\n",
    "# sim_matrix_smoothed = smooth_surface_graph(graph, sim_matrix_sum, iterations=5)\n",
    "\n",
    "# # 3 : Compute the gradient of the similarty matrix\n",
    "# gradients = compute_gradients(graph, sim_matrix_smoothed)\n",
    "# gradients_sum = gradients.sum(axis=1).astype(np.float32) # TODO : HERE is the diff between my way and gordon way\n",
    "\n",
    "# # 3.1 : Smooth the gradient\n",
    "# gradient_smoothed = smooth_surface_graph(graph, gradients_sum, iterations=10)\n",
    "# gradients_path = config[\"subjects_dir\"] / f\"gradients_group_run{run}_{hemisphere}.npy\"\n",
    "# np.save(gradients_path, gradients)\n",
    "\n",
    "# # 4 : Compute the watershed of each gradients to optain gradient maps\n",
    "# labels = watershed_by_flooding(graph, gradient_smoothed)\n",
    "# labels_path = config[\"subjects_dir\"] / f\"labels_group_run{run}_{hemisphere}.npy\"\n",
    "# np.save(labels_path, labels)\n",
    "\n",
    "# # 5 : Visualize the watershed\n",
    "# # visualize_brain_surface(coords_, faces_, gradient_smoothed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline GORDON WAY\n",
    "config = {\n",
    "\"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "\"subjects_dir\": Path(r\"D:\\Data_Conn_Preproc\\PPSFACE_N18\")\n",
    "}\n",
    "run = 1\n",
    "\n",
    "for hemisphere in ['lh', 'rh']:\n",
    "    \n",
    "    surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.white\"\n",
    "    surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.inflated\"\n",
    "    # Extract the Surface Mesh\n",
    "    coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "    coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "    graph = build_mesh_graph(faces)\n",
    "\n",
    "    # Output paths\n",
    "    output_dir = config[\"subjects_dir\"] / \"group_parcellation\"\n",
    "    (output_dir).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "\n",
    "    # 1 : Compute the average similartiy matrix across each subjects\n",
    "    sim_matrix_sum = np.zeros(nx.adjacency_matrix(graph).shape, dtype=np.float32)\n",
    "    print('sim_matrix_sum shape', sim_matrix_sum.shape)\n",
    "    for i in range(1,19):\n",
    "        # if i == 5:\n",
    "        #     continue # Subject 5 is missing PPSFACE20\n",
    "        \n",
    "        # >>>>>>>>>>>>>>>>>>> To modify if needed\n",
    "        # Variables path\n",
    "        subject = f\"{i:02d}\"\n",
    "        subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "\n",
    "        # Define paths using pathlib\n",
    "        surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "        vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "        brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "        # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "        \n",
    "        # Load the data\n",
    "        surf_fmri_n, vol_fmri_n = load_data_normalized(surf_fmri_path,\n",
    "                                                       vol_fmri_path, \n",
    "                                                       brain_mask_path)\n",
    "        \n",
    "        sim_matrix_sum += compute_similarity_matrix_pca(vol_fmri_n,\n",
    "                                                       surf_fmri_n)\n",
    "\n",
    "    # Save the similarty matrix\n",
    "    sim_matrix_path = output_dir / f\"similarity_matrix_group_run{run}_{hemisphere}.npy\"\n",
    "    np.save(sim_matrix_path, sim_matrix_sum)\n",
    "    \n",
    "        \n",
    "    # 2 : Smooth the similatry matrix\n",
    "    sim_matrix_smoothed = smooth_surface_graph(graph, sim_matrix_sum, iterations=5)\n",
    "\n",
    "    # 3 : Compute the gradient of the similarty matrix\n",
    "    gradients = compute_gradients(graph, sim_matrix_smoothed)\n",
    "\n",
    "    # 3.1 : Smooth the gradient\n",
    "    gradients_smoothed = smooth_surface_graph(graph, gradients, iterations=10)\n",
    "    gradients_path = output_dir / f\"gradients_smoothed_group_run{run}_{hemisphere}.npy\"\n",
    "    np.save(gradients_path, gradients_smoothed)\n",
    "\n",
    "\n",
    "    # 4 : Create the boundary map from the watershed\n",
    "    boundary_map = np.zeros_like(gradients[:,0]).astype(np.float32)\n",
    "    for map_idx in range(gradients.shape[1]): # loop over each columns of the matrix\n",
    "        if map_idx % 10 == 0:\n",
    "            print(f\"Processing map {map_idx}\") # Print the current map index\n",
    "        boundary = (watershed_by_flooding(graph, gradients_smoothed[:,map_idx])<0)*1 # Extract the bounary from the watershed algorithm\n",
    "        boundary_map += boundary\n",
    "    \n",
    "    boundary_map_path = output_dir / f\"boundary_map_group_run{run}_{hemisphere}.npy\"\n",
    "    np.save(boundary_map_path, boundary_map)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 : Visualize the bounardy map\n",
    "visualize_brain_surface(coords_, faces_, boundary_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
