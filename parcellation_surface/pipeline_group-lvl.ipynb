{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO : create a parcellation from the average of the similatriy matrix,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import nibabel as nib \n",
    "import networkx as nx\n",
    "\n",
    "from similarity_matrix import compute_similarity_matrix_pca\n",
    "from smoothing import smooth_surface_graph\n",
    "from gradient import compute_gradients, build_mesh_graph\n",
    "from watershed import watershed_by_flooding\n",
    "from visualization import visualize_brain_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path Run all subject lh on run 1\n",
    "\n",
    "# config = {\n",
    "# \"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "# \"subjects_dir\": Path(r\"D:\\Data_Conn_Preproc\\PPSFACE_N20\")\n",
    "# }\n",
    "\n",
    "# hemisphere = 'lh'\n",
    "# run = 2\n",
    "\n",
    "# surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.white\"\n",
    "# surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.inflated\"\n",
    "# # Extract the Surface Mesh\n",
    "# coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "# coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "# graph = build_mesh_graph(faces)\n",
    "\n",
    "# # Output paths\n",
    "# output_gradient_dir = config[\"subjects_dir\"] / \"gradient\"\n",
    "# (output_gradient_dir).mkdir(exist_ok=True, parents=True)\n",
    "# output_labels_dir = config[\"subjects_dir\"] / \"labels\"\n",
    "# (output_labels_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "\n",
    "# # Variables path\n",
    "# subject = f\"{1:02d}\"\n",
    "# subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "\n",
    "# # Define paths using pathlib\n",
    "# surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "# vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "# brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "\n",
    "\n",
    "# # If needed, the grey matter mask\n",
    "# # gm_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / f\"{hemisphere}.ribbon.mgz\"\n",
    "\n",
    "\n",
    "# print('all paths defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import resample_img\n",
    "def load_data_normalized(surf_fmri_path,\n",
    "                         vol_fmri_path, \n",
    "                         brain_mask_path):\n",
    "\n",
    "    # Load the surface data\n",
    "    surf_fmri = nib.load(str(surf_fmri_path)).get_fdata().squeeze()\n",
    "    surf_fmri_n = (surf_fmri - np.mean(surf_fmri, axis=1, keepdims=True)) / np.std(surf_fmri, axis=1, keepdims=True)\n",
    "    \n",
    "    # Load the images using nibabel\n",
    "    vol_fmri = nib.load(str(vol_fmri_path))\n",
    "    mask_img = nib.load(brain_mask_path)\n",
    "\n",
    "    # resample the mask to the right one\n",
    "    mask_img = resample_img(\n",
    "        mask_img,\n",
    "        target_affine=vol_fmri.affine,\n",
    "        target_shape=vol_fmri.get_fdata().shape[:-1],\n",
    "        interpolation='nearest',\n",
    "        force_resample=True\n",
    "    )\n",
    "\n",
    "    fmri_data = vol_fmri.get_fdata()\n",
    "    mask_data = mask_img.get_fdata().astype(bool)  # Convert mask to boolean\n",
    "    # Normalize the data\n",
    "    vol_fmri = fmri_data[mask_data] \n",
    "    vol_fmri_n = (vol_fmri - np.mean(vol_fmri, axis=1, keepdims=True)) / np.std(vol_fmri, axis=1, keepdims=True)\n",
    "    \n",
    "    # Remove nans from the data\n",
    "    surf_fmri_n = np.nan_to_num(surf_fmri_n).astype(np.float32)\n",
    "    vol_fmri_n = np.nan_to_num(vol_fmri_n).astype(np.float32)\n",
    "    return surf_fmri_n, vol_fmri_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Full pipeline my way\n",
    "    \n",
    "# # 1 : Compute the average similartiy matrix across each subjects\n",
    "# sim_matrix_sum = np.zeros(nx.adjacency_matrix(graph).shape, dtype=np.float32)\n",
    "# print('sim_matrix_sum shape', sim_matrix_sum.shape)\n",
    "# for i in range(1,21):\n",
    "#     if i == 5:\n",
    "#         continue # Subject 5 is missing\n",
    "#     # Variables path\n",
    "#     subject = f\"{i:02d}\"\n",
    "#     subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "\n",
    "#     # Define paths using pathlib\n",
    "#     surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "#     vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "#     brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "\n",
    "#     # Load the data\n",
    "#     surf_fmri_n, vol_fmri_n = load_data_normalized(surf_fmri_path,\n",
    "#                                                     vol_fmri_path, \n",
    "#                                                     brain_mask_path)\n",
    "    \n",
    "#     sim_matrix_sum += compute_similarty_matrix_PCA(vol_fmri_n,\n",
    "#                                                 surf_fmri_n)\n",
    "\n",
    "# # Save the similarty matrix\n",
    "# sim_matrix_path = config[\"subjects_dir\"] / f\"similarity_matrix_group_run{run}_{hemisphere}.npy\"\n",
    "# np.save(sim_matrix_path, sim_matrix_sum)\n",
    "    \n",
    "    \n",
    "# # 2 : Smooth the similatry matrix\n",
    "# sim_matrix_smoothed = smooth_surface_graph(graph, sim_matrix_sum, iterations=5)\n",
    "\n",
    "# # 3 : Compute the gradient of the similarty matrix\n",
    "# gradients = compute_gradients(graph, sim_matrix_smoothed)\n",
    "# gradients_sum = gradients.sum(axis=1).astype(np.float32) # TODO : HERE is the diff between my way and gordon way\n",
    "\n",
    "# # 3.1 : Smooth the gradient\n",
    "# gradient_smoothed = smooth_surface_graph(graph, gradients_sum, iterations=10)\n",
    "# gradients_path = config[\"subjects_dir\"] / f\"gradients_group_run{run}_{hemisphere}.npy\"\n",
    "# np.save(gradients_path, gradients)\n",
    "\n",
    "# # 4 : Compute the watershed of each gradients to optain gradient maps\n",
    "# labels = watershed_by_flooding(graph, gradient_smoothed)\n",
    "# labels_path = config[\"subjects_dir\"] / f\"labels_group_run{run}_{hemisphere}.npy\"\n",
    "# np.save(labels_path, labels)\n",
    "\n",
    "# # 5 : Visualize the watershed\n",
    "# # visualize_brain_surface(coords_, faces_, gradient_smoothed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline GORDON WAY\n",
    "config = {\n",
    "\"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "\"subjects_dir\": Path(r\"D:\\Data_Conn_Preproc\\PPSFACE_N18\")\n",
    "}\n",
    "run = 2\n",
    "\n",
    "for hemisphere in ['lh', 'rh']:\n",
    "    \n",
    "    surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.white\"\n",
    "    surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"{hemisphere}.inflated\"\n",
    "    # Extract the Surface Mesh\n",
    "    coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "    coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "    graph = build_mesh_graph(faces)\n",
    "\n",
    "    # Output paths\n",
    "    output_dir = config[\"subjects_dir\"] / \"group_parcellation\"\n",
    "    (output_dir).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # 1 : Compute the average similartiy matrix across each subjects\n",
    "    sim_matrix_sum = np.zeros(nx.adjacency_matrix(graph).shape, dtype=np.float32)\n",
    "    print('sim_matrix_sum shape', sim_matrix_sum.shape)\n",
    "    for i in range(1,19):\n",
    "        # if i == 5:\n",
    "        #     continue # Subject 5 is missing PPSFACE20\n",
    "        \n",
    "        # >>>>>>>>>>>>>>>>>>> To modify if needed\n",
    "        # Variables path\n",
    "        subject = f\"{i:02d}\"\n",
    "        subj_dir = config[\"subjects_dir\"] / f\"sub-{subject}\"\n",
    "\n",
    "        # Define paths using pathlib\n",
    "        surf_fmri_path = subj_dir / \"func\" / f\"surf_conn_sub{subject}_run{run}_{hemisphere}.func.fsaverage6.mgh\"\n",
    "        vol_fmri_path = subj_dir / \"func\" / f\"niftiDATA_Subject{subject}_Condition000_run{run}.nii.gz\"\n",
    "        brain_mask_path = subj_dir / f\"sub{subject}_freesurfer\" / \"mri\" / \"brainmask.mgz\"\n",
    "        # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "        \n",
    "        # Load the data\n",
    "        surf_fmri_n, vol_fmri_n = load_data_normalized(surf_fmri_path,\n",
    "                                                       vol_fmri_path, \n",
    "                                                       brain_mask_path)\n",
    "        \n",
    "        sim_matrix_sum += compute_similarity_matrix_pca(vol_fmri_n,\n",
    "                                                       surf_fmri_n)\n",
    "\n",
    "    # Save the similarty matrix\n",
    "    sim_matrix_path = output_dir / f\"similarity_matrix_group_run{run}_{hemisphere}.npy\"\n",
    "    np.save(sim_matrix_path, sim_matrix_sum)\n",
    "    \n",
    "    \n",
    "    # 2 : Smooth the similatry matrix\n",
    "    sim_matrix_smoothed = smooth_surface_graph(graph, sim_matrix_sum, iterations=5)\n",
    "\n",
    "    # 3 : Compute the gradient of the similarty matrix\n",
    "    gradients = compute_gradients(graph, sim_matrix_smoothed)\n",
    "\n",
    "    # 3.1 : Smooth the gradient\n",
    "    gradients_smoothed = smooth_surface_graph(graph, gradients, iterations=10)\n",
    "    gradients_path = output_dir / f\"gradients_smoothed_group_run{run}_{hemisphere}.npy\"\n",
    "    np.save(gradients_path, gradients_smoothed)\n",
    "\n",
    "\n",
    "    # 4 : Create the boundary map from the watershed\n",
    "    boundary_map = np.zeros_like(gradients[:,0]).astype(np.float32)\n",
    "    for map_idx in range(gradients.shape[1]): # loop over each columns of the matrix\n",
    "        if map_idx % 10 == 0:\n",
    "            print(f\"Processing map {map_idx}\") # Print the current map index\n",
    "        boundary = (watershed_by_flooding(graph, gradients_smoothed[:,map_idx])<0)*1 # Extract the bounary from the watershed algorithm\n",
    "        boundary_map += boundary\n",
    "    \n",
    "    boundary_map_path = output_dir / f\"boundary_map_group_run{run}_{hemisphere}.npy\"\n",
    "    np.save(boundary_map_path, boundary_map)\n",
    "\n",
    "    # Create the FINAL parcels\n",
    "    bound_smoothed = smooth_surface_graph(graph, boundary_map, iterations=10)\n",
    "    label_bound = watershed_by_flooding(graph, bound_smoothed)\n",
    "    # Save the parcels\n",
    "    np.save(output_dir / f\"labels_group_run12_smooth10_run{run}_{hemisphere}.npy\", label_bound)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING BEFOR USING THIS SCRIPT\n",
    "\"\"\"\n",
    "This part is used in order to create a parcellation from the run1 and run2.\n",
    "\"\"\"\n",
    "ppsface = \"PPSFACE_N20\"\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "   surface_path = f\"D:\\Data_Conn_Preproc\\\\fsaverage6\\surf\\{hemi}.white\"\n",
    "   inf_path = f\"D:\\Data_Conn_Preproc\\\\fsaverage6\\surf\\{hemi}.inflated\"\n",
    "   # surface_path = r\"D:\\Data_Conn_Preproc\\fsaverage6\\surf\\rh.inflated\"\n",
    "   coords, faces = nib.freesurfer.read_geometry(surface_path)\n",
    "   coords_, faces_ = nib.freesurfer.read_geometry(inf_path)\n",
    "   graph = build_mesh_graph(faces)\n",
    "   bound_sum = 0\n",
    "   for run in [\"1\",\"2\"]:\n",
    "      # Extract the parcellation\n",
    "      bound_sum += np.load(f\"D:\\Data_Conn_Preproc\\{ppsface}\\group_parcellation\\\\boundary_map_group_run{run}_{hemi}.npy\")\n",
    "        \n",
    "   # Create the parcels\n",
    "   bound_smoothed = smooth_surface_graph(graph, bound_sum, iterations=10)\n",
    "   label_bound = watershed_by_flooding(graph, bound_smoothed)\n",
    "   # Save the parcels\n",
    "   np.save(f\"D:\\Data_Conn_Preproc\\{ppsface}\\group_parcellation\\labels_group_run12_smooth10_{hemi}.npy\", label_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 : Visualize the bounardy map\n",
    "config = {\n",
    "\"fsavg6_dir\": Path(r\"D:\\Data_Conn_Preproc\\fsaverage6\"),\n",
    "\"subjects_dir\": Path(r\"D:\\Data_Conn_Preproc\\PPSFACE_N20\")\n",
    "}\n",
    "run = 2\n",
    "surface_inf_path = config[\"fsavg6_dir\"] / \"surf\" / f\"lh.inflated\"\n",
    "surface_path = config[\"fsavg6_dir\"] / \"surf\" / f\"lh.white\"\n",
    "\n",
    "coords_, faces_ = nib.freesurfer.read_geometry(str(surface_inf_path))\n",
    "coords, faces = nib.freesurfer.read_geometry(str(surface_path))\n",
    "graph = build_mesh_graph(faces)\n",
    "\n",
    "path_bound1 = r\"D:\\Data_Conn_Preproc\\PPSFACE_N20\\group_parcellation\\boundary_map_group_run1_lh.npy\"\n",
    "path_bound2 = r\"D:\\Data_Conn_Preproc\\PPSFACE_N20\\group_parcellation\\boundary_map_group_run2_lh.npy\"\n",
    "boundary_map1 = np.load(path_bound1)\n",
    "boundary_map2 = np.load(path_bound2)\n",
    "\n",
    "# put the 2 runs together\n",
    "boundary_map = boundary_map1 \n",
    "\n",
    "print('boundary_map shape', boundary_map1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_brain_surface(coords_, faces_, boundary_map, title='Bounardy Map lh PPSFACE20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_smoothed = smooth_surface_graph(graph, boundary_map, iterations=10)\n",
    "visualize_brain_surface(coords_, faces_, bound_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = watershed_by_flooding(graph, bound_smoothed)\n",
    "visualize_brain_surface(coords_, faces_, labels, title=\"Group-Level Parcellation lh PPSFACE20\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
